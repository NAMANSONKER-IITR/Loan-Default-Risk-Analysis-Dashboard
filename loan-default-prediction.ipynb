{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eec6266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T17:19:03.943361Z",
     "iopub.status.busy": "2025-04-28T17:19:03.942992Z",
     "iopub.status.idle": "2025-04-28T17:19:03.947325Z",
     "shell.execute_reply": "2025-04-28T17:19:03.946145Z",
     "shell.execute_reply.started": "2025-04-28T17:19:03.943330Z"
    },
    "papermill": {
     "duration": 0.01014,
     "end_time": "2025-04-28T23:17:56.975553",
     "exception": false,
     "start_time": "2025-04-28T23:17:56.965413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Project: Loan Default Prediction System\n",
    "## Author: Hassan Saifuddin\n",
    "## Date: 28/4/2025\n",
    "## Description: A machine learning model to predict loan default risks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c428960",
   "metadata": {
    "papermill": {
     "duration": 0.008624,
     "end_time": "2025-04-28T23:17:56.993542",
     "exception": false,
     "start_time": "2025-04-28T23:17:56.984918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0bbc01",
   "metadata": {
    "papermill": {
     "duration": 0.008585,
     "end_time": "2025-04-28T23:17:57.011166",
     "exception": false,
     "start_time": "2025-04-28T23:17:57.002581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Data Documentation:\n",
    "The dataset consists of various features that describe loan applicants, their financial background, and other demographic information. Below is a detailed description of each column used in the analysis:\n",
    "\n",
    "1. Age\n",
    "Type: Numeric\n",
    "\n",
    "Description: The age of the loan applicant in years.\n",
    "\n",
    "Importance: Age is often an important factor when assessing loan eligibility or predicting the likelihood of default. Older individuals may have more stable income and less risk of default, but this is not always the case.\n",
    "\n",
    "2. Income\n",
    "Type: Numeric\n",
    "\n",
    "Description: The annual income of the loan applicant in dollars.\n",
    "\n",
    "Importance: Income is a key factor in evaluating an applicant’s ability to repay a loan. Higher income generally correlates with a lower risk of default.\n",
    "\n",
    "3. LoanAmount\n",
    "Type: Numeric\n",
    "\n",
    "Description: The total loan amount requested by the applicant.\n",
    "\n",
    "Importance: The loan amount can influence the risk of default. Larger loans may carry higher risks, particularly if the applicant's income is not substantial enough to support it.\n",
    "\n",
    "4. CreditScore\n",
    "Type: Numeric\n",
    "\n",
    "Description: The credit score of the loan applicant.\n",
    "\n",
    "Importance: Credit score is one of the most important indicators of creditworthiness. A higher score generally means lower risk, as the applicant has a history of managing credit responsibly.\n",
    "\n",
    "5. MonthsEmployed\n",
    "Type: Numeric\n",
    "\n",
    "Description: The number of months the applicant has been employed at their current job.\n",
    "\n",
    "Importance: This feature provides an indication of job stability. Longer employment may correlate with a stable income and, consequently, a lower risk of loan default.\n",
    "\n",
    "6. NumCreditLines\n",
    "Type: Numeric\n",
    "\n",
    "Description: The number of credit lines (e.g., credit cards, mortgages) the applicant currently holds.\n",
    "\n",
    "Importance: A higher number of credit lines could indicate a greater level of financial responsibility or the possibility of overextension of credit.\n",
    "\n",
    "7. InterestRate\n",
    "Type: Numeric\n",
    "\n",
    "Description: The interest rate applied to the loan.\n",
    "\n",
    "Importance: A higher interest rate may indicate greater financial risk or less favorable terms for the applicant, often associated with a higher likelihood of default.\n",
    "\n",
    "8. LoanTerm\n",
    "Type: Numeric\n",
    "\n",
    "Description: The loan term in months.\n",
    "\n",
    "Importance: Loan term affects monthly payments and total interest paid. Shorter loan terms may have higher monthly payments but lower total interest, while longer terms may have lower payments but higher total interest.\n",
    "\n",
    "9. DTIRatio (Debt-to-Income Ratio)\n",
    "Type: Numeric\n",
    "\n",
    "Description: The ratio of the applicant's total debt to their income.\n",
    "\n",
    "Importance: This is a critical indicator of an applicant’s ability to repay the loan. A higher DTI ratio indicates that the applicant may already be financially stretched and at higher risk of default.\n",
    "\n",
    "10. Default\n",
    "Type: Categorical (Binary)\n",
    "\n",
    "Description: The target variable indicating whether the loan applicant defaulted (1) or did not default (0).\n",
    "\n",
    "Importance: This is the outcome we are trying to predict. The model uses other features in the dataset to predict this variable.\n",
    "\n",
    "11. Education\n",
    "Type: Categorical\n",
    "\n",
    "Description: The highest level of education attained by the applicant.\n",
    "\n",
    "Categories:\n",
    "\n",
    "0: No formal education\n",
    "\n",
    "1: High school or equivalent\n",
    "\n",
    "2: Undergraduate degree\n",
    "\n",
    "3: Postgraduate degree\n",
    "\n",
    "Importance: Education level can affect earning potential and financial stability, potentially influencing the risk of loan default.\n",
    "\n",
    "12. EmploymentType\n",
    "Type: Categorical\n",
    "\n",
    "Description: The type of employment the applicant has.\n",
    "\n",
    "Categories:\n",
    "\n",
    "0: Unemployed\n",
    "\n",
    "1: Self-employed\n",
    "\n",
    "2: Employed full-time\n",
    "\n",
    "Importance: Employment type may indicate the stability of income. Self-employed individuals might experience income volatility, while full-time employed individuals generally have more stable incomes.\n",
    "\n",
    "13. MaritalStatus\n",
    "Type: Categorical\n",
    "\n",
    "Description: The marital status of the applicant.\n",
    "\n",
    "Categories:\n",
    "\n",
    "0: Single\n",
    "\n",
    "1: Married\n",
    "\n",
    "2: Divorced\n",
    "\n",
    "Importance: Marital status can influence financial stability. Married individuals may have dual incomes or shared financial responsibilities, while single individuals may bear all financial responsibility themselves.\n",
    "\n",
    "14. HasMortgage\n",
    "Type: Categorical (Binary)\n",
    "\n",
    "Description: Indicates whether the applicant currently has a mortgage.\n",
    "\n",
    "Categories:\n",
    "\n",
    "0: No mortgage\n",
    "\n",
    "1: Has mortgage\n",
    "\n",
    "Importance: Having a mortgage implies an existing financial obligation, which could affect the applicant's ability to repay new loans.\n",
    "\n",
    "15. HasDependents\n",
    "Type: Categorical (Binary)\n",
    "\n",
    "Description: Indicates whether the applicant has dependents (e.g., children, other dependents).\n",
    "\n",
    "Categories:\n",
    "\n",
    "0: No dependents\n",
    "\n",
    "1: Has dependents\n",
    "\n",
    "Importance: Applicants with dependents may face higher living costs, which could reduce their available income for repaying loans.\n",
    "\n",
    "16. LoanPurpose\n",
    "Type: Categorical\n",
    "\n",
    "Description: The purpose for which the loan is being requested.\n",
    "\n",
    "Categories:\n",
    "\n",
    "0: Home purchase\n",
    "\n",
    "1: Debt consolidation\n",
    "\n",
    "2: Education\n",
    "\n",
    "3: Medical expenses\n",
    "\n",
    "Importance: The purpose of the loan can affect the applicant’s likelihood of default. Loans for essential purposes like home purchase or medical expenses may have a different repayment pattern than those for discretionary purposes like education.\n",
    "\n",
    "17. HasCoSigner\n",
    "Type: Categorical (Binary)\n",
    "\n",
    "Description: Indicates whether the applicant has a co-signer for the loan.\n",
    "\n",
    "Categories:\n",
    "\n",
    "0: No co-signer\n",
    "\n",
    "1: Has co-signer\n",
    "\n",
    "Importance: Having a co-signer reduces the risk of default because the co-signer is responsible for repayment in case the primary borrower defaults."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea886b3d",
   "metadata": {
    "papermill": {
     "duration": 0.00847,
     "end_time": "2025-04-28T23:17:57.028630",
     "exception": false,
     "start_time": "2025-04-28T23:17:57.020160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CORE SYSTEM MODULES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e454fc01",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-28T23:17:57.047806Z",
     "iopub.status.busy": "2025-04-28T23:17:57.047413Z",
     "iopub.status.idle": "2025-04-28T23:18:00.370012Z",
     "shell.execute_reply": "2025-04-28T23:18:00.368734Z"
    },
    "papermill": {
     "duration": 3.334582,
     "end_time": "2025-04-28T23:18:00.372097",
     "exception": false,
     "start_time": "2025-04-28T23:17:57.037515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import zipfile\n",
    "# Module to handle extraction and management of ZIP compressed files.\n",
    "\n",
    "import pandas as pd\n",
    "# Primary library for structured data handling using DataFrames.\n",
    "\n",
    "import numpy as np\n",
    "# Essential package for numerical computing and array operations.\n",
    "\n",
    "# =============================================================================\n",
    "# MACHINE LEARNING MODEL ARCHITECTURE\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Ensemble learning method: Builds multiple decision trees and merges their results for better accuracy and stability.\n",
    "\n",
    "# =============================================================================\n",
    "# DATA PREPROCESSING AND FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "# - StandardScaler: Normalize features by removing the mean and scaling to unit variance.\n",
    "# - OneHotEncoder: Encode categorical features as a one-hot numeric array.\n",
    "# - PolynomialFeatures: Generate new polynomial and interaction features to capture non-linear relationships.\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL VALIDATION AND HYPERPARAMETER OPTIMIZATION\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "# - train_test_split: Partition data into training and testing sets.\n",
    "# - cross_val_score: Evaluate model performance via cross-validation.\n",
    "# - GridSearchCV: Exhaustive search over specified parameter values for an estimator.\n",
    "\n",
    "# =============================================================================\n",
    "# PIPELINING AND DATA TRANSFORMATION\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.pipeline import Pipeline as pipeline\n",
    "# Pipeline: Assemble several steps (preprocessing + model) into one sequential object.\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# Apply different preprocessing pipelines to different feature columns.\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL EVALUATION METRICS\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "# - accuracy_score: Calculates the ratio of correctly predicted observations to total observations.\n",
    "# - make_scorer: Create a custom scoring function for model evaluation or hyperparameter tuning.\n",
    "\n",
    "# =============================================================================\n",
    "# HANDLING IMBALANCED DATASETS\n",
    "# =============================================================================\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "# - RandomOverSampler: Duplicate random records from the minority class to balance the dataset.\n",
    "# - SMOTE (Synthetic Minority Over-sampling Technique): Create synthetic examples of the minority class.\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Randomly remove samples from the majority class to balance the class distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217543c2",
   "metadata": {
    "papermill": {
     "duration": 0.008673,
     "end_time": "2025-04-28T23:18:00.390179",
     "exception": false,
     "start_time": "2025-04-28T23:18:00.381506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this step, we are importing the necessary libraries to carry out data preprocessing, modeling, and evaluation. These libraries serve the following purposes:\n",
    "\n",
    "pandas and numpy: Used for data manipulation and numerical operations, like handling missing data, transformation, and reshaping.\n",
    "\n",
    "sklearn: Includes functions for model creation (e.g., RandomForestClassifier), data preprocessing (e.g., StandardScaler, OneHotEncoder), and model evaluation (e.g., accuracy_score).\n",
    "\n",
    "imblearn: Provides tools for handling class imbalances using techniques like SMOTE and RandomOverSampler.\n",
    "\n",
    "These libraries enable various tasks such as data transformation, model fitting, hyperparameter tuning, and performance evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb121b7e",
   "metadata": {
    "papermill": {
     "duration": 0.008831,
     "end_time": "2025-04-28T23:18:00.408039",
     "exception": false,
     "start_time": "2025-04-28T23:18:00.399208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 1: Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9217c42f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:18:00.427921Z",
     "iopub.status.busy": "2025-04-28T23:18:00.427385Z",
     "iopub.status.idle": "2025-04-28T23:18:00.432167Z",
     "shell.execute_reply": "2025-04-28T23:18:00.430950Z"
    },
    "papermill": {
     "duration": 0.016801,
     "end_time": "2025-04-28T23:18:00.434231",
     "exception": false,
     "start_time": "2025-04-28T23:18:00.417430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the file path for the input dataset.\n",
    "file_location = '/kaggle/input/loan-default/Loan_default.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e5b545",
   "metadata": {
    "papermill": {
     "duration": 0.008748,
     "end_time": "2025-04-28T23:18:00.452077",
     "exception": false,
     "start_time": "2025-04-28T23:18:00.443329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 2: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b461dab3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:18:00.471368Z",
     "iopub.status.busy": "2025-04-28T23:18:00.470984Z",
     "iopub.status.idle": "2025-04-28T23:18:01.521060Z",
     "shell.execute_reply": "2025-04-28T23:18:01.519942Z"
    },
    "papermill": {
     "duration": 1.062078,
     "end_time": "2025-04-28T23:18:01.523037",
     "exception": false,
     "start_time": "2025-04-28T23:18:00.460959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LoanID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>MonthsEmployed</th>\n",
       "      <th>NumCreditLines</th>\n",
       "      <th>InterestRate</th>\n",
       "      <th>LoanTerm</th>\n",
       "      <th>DTIRatio</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmploymentType</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HasMortgage</th>\n",
       "      <th>HasDependents</th>\n",
       "      <th>LoanPurpose</th>\n",
       "      <th>HasCoSigner</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I38PQUQS96</td>\n",
       "      <td>56</td>\n",
       "      <td>85994</td>\n",
       "      <td>50587</td>\n",
       "      <td>520</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>15.23</td>\n",
       "      <td>36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Other</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HPSK72WA7R</td>\n",
       "      <td>69</td>\n",
       "      <td>50432</td>\n",
       "      <td>124440</td>\n",
       "      <td>458</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4.81</td>\n",
       "      <td>60</td>\n",
       "      <td>0.68</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Other</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1OZ6DPJ8Y</td>\n",
       "      <td>46</td>\n",
       "      <td>84208</td>\n",
       "      <td>129188</td>\n",
       "      <td>451</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>21.17</td>\n",
       "      <td>24</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Auto</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V2KKSFM3UN</td>\n",
       "      <td>32</td>\n",
       "      <td>31713</td>\n",
       "      <td>44799</td>\n",
       "      <td>743</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.07</td>\n",
       "      <td>24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>High School</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Married</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Business</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EY08JDHTZP</td>\n",
       "      <td>60</td>\n",
       "      <td>20437</td>\n",
       "      <td>9139</td>\n",
       "      <td>633</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6.51</td>\n",
       "      <td>48</td>\n",
       "      <td>0.73</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Auto</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LoanID  Age  Income  LoanAmount  CreditScore  MonthsEmployed  \\\n",
       "0  I38PQUQS96   56   85994       50587          520              80   \n",
       "1  HPSK72WA7R   69   50432      124440          458              15   \n",
       "2  C1OZ6DPJ8Y   46   84208      129188          451              26   \n",
       "3  V2KKSFM3UN   32   31713       44799          743               0   \n",
       "4  EY08JDHTZP   60   20437        9139          633               8   \n",
       "\n",
       "   NumCreditLines  InterestRate  LoanTerm  DTIRatio    Education  \\\n",
       "0               4         15.23        36      0.44   Bachelor's   \n",
       "1               1          4.81        60      0.68     Master's   \n",
       "2               3         21.17        24      0.31     Master's   \n",
       "3               3          7.07        24      0.23  High School   \n",
       "4               4          6.51        48      0.73   Bachelor's   \n",
       "\n",
       "  EmploymentType MaritalStatus HasMortgage HasDependents LoanPurpose  \\\n",
       "0      Full-time      Divorced         Yes           Yes       Other   \n",
       "1      Full-time       Married          No            No       Other   \n",
       "2     Unemployed      Divorced         Yes           Yes        Auto   \n",
       "3      Full-time       Married          No            No    Business   \n",
       "4     Unemployed      Divorced          No           Yes        Auto   \n",
       "\n",
       "  HasCoSigner  Default  \n",
       "0         Yes        0  \n",
       "1         Yes        0  \n",
       "2          No        1  \n",
       "3          No        0  \n",
       "4          No        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the CSV data directly into a pandas DataFrame.\n",
    "Data = pd.read_csv(file_location)\n",
    "\n",
    "# Preview the first few rows to confirm successful loading.\n",
    "Data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d08620a",
   "metadata": {
    "papermill": {
     "duration": 0.008917,
     "end_time": "2025-04-28T23:18:01.541934",
     "exception": false,
     "start_time": "2025-04-28T23:18:01.533017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here, we load the dataset from a CSV file into a pandas DataFrame. This allows us to perform all data manipulation and analysis within Python. read_csv() is a common function in pandas to load CSV files into DataFrame format for easy processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ebb2dd",
   "metadata": {
    "papermill": {
     "duration": 0.008932,
     "end_time": "2025-04-28T23:18:01.560279",
     "exception": false,
     "start_time": "2025-04-28T23:18:01.551347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 3: Data Cleaning - Drop Irrelevant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9786dd39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:18:01.580461Z",
     "iopub.status.busy": "2025-04-28T23:18:01.580081Z",
     "iopub.status.idle": "2025-04-28T23:18:01.607667Z",
     "shell.execute_reply": "2025-04-28T23:18:01.606416Z"
    },
    "papermill": {
     "duration": 0.040106,
     "end_time": "2025-04-28T23:18:01.609729",
     "exception": false,
     "start_time": "2025-04-28T23:18:01.569623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Data Shape: (255347, 17)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Drop the 'LoanID' column as it is an identifier and not useful for prediction.\n",
    "Data = Data.drop(columns='LoanID')\n",
    "\n",
    "# Verify that the column has been dropped by checking the DataFrame shape.\n",
    "print(\"Updated Data Shape:\", Data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164ef2d",
   "metadata": {
    "papermill": {
     "duration": 0.009874,
     "end_time": "2025-04-28T23:18:01.630568",
     "exception": false,
     "start_time": "2025-04-28T23:18:01.620694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this step, we drop the 'LoanID' column from the dataset. Often, certain columns are identifiers that don’t provide useful information for modeling, and dropping them can reduce noise and improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c15c4f",
   "metadata": {
    "papermill": {
     "duration": 0.008919,
     "end_time": "2025-04-28T23:18:01.648976",
     "exception": false,
     "start_time": "2025-04-28T23:18:01.640057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 4: Data Preprocessing - Select Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d638058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:18:01.668949Z",
     "iopub.status.busy": "2025-04-28T23:18:01.668558Z",
     "iopub.status.idle": "2025-04-28T23:18:01.677312Z",
     "shell.execute_reply": "2025-04-28T23:18:01.675895Z"
    },
    "papermill": {
     "duration": 0.020943,
     "end_time": "2025-04-28T23:18:01.679426",
     "exception": false,
     "start_time": "2025-04-28T23:18:01.658483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Numerical Features: ['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio', 'Default']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Select numerical columns (int and float types) for further analysis and model training.\n",
    "num = Data.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "# Display the selected numerical features to verify.\n",
    "print(\"Selected Numerical Features:\", num.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e86cd",
   "metadata": {
    "papermill": {
     "duration": 0.009002,
     "end_time": "2025-04-28T23:18:01.698240",
     "exception": false,
     "start_time": "2025-04-28T23:18:01.689238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We separate the numerical columns (e.g., int, float) and categorical columns (e.g., strings or objects) into different DataFrames.\n",
    "\n",
    "Numerical columns are used for mathematical operations like scaling or feature selection.\n",
    "\n",
    "Categorical columns require encoding into numerical representations before feeding them into machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4708aa2",
   "metadata": {
    "papermill": {
     "duration": 0.009034,
     "end_time": "2025-04-28T23:18:01.716733",
     "exception": false,
     "start_time": "2025-04-28T23:18:01.707699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 5: Feature Engineering - Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d33ae16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:18:01.736717Z",
     "iopub.status.busy": "2025-04-28T23:18:01.736379Z",
     "iopub.status.idle": "2025-04-28T23:18:01.744255Z",
     "shell.execute_reply": "2025-04-28T23:18:01.742940Z"
    },
    "papermill": {
     "duration": 0.020065,
     "end_time": "2025-04-28T23:18:01.746263",
     "exception": false,
     "start_time": "2025-04-28T23:18:01.726198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def ColumnTrans(cat):\n",
    "    \"\"\"\n",
    "    Function to convert categorical variables into numerical variables\n",
    "    by mapping unique values to integer indices.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    cat : DataFrame\n",
    "        A pandas DataFrame containing categorical columns to be transformed.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    cat : DataFrame\n",
    "        The original DataFrame with categorical columns transformed into numerical values.\n",
    "    \"\"\"\n",
    "    # Iterate over each column in the DataFrame.\n",
    "    for column in cat.columns:\n",
    "        # Get unique values for the column\n",
    "        unique_values = cat[column].unique()\n",
    "        \n",
    "        # Create a mapping of each unique value to a corresponding integer\n",
    "        value_map = {value: index for index, value in enumerate(unique_values)}\n",
    "        \n",
    "        # Map the column's categorical values to their integer indices\n",
    "        cat[column] = cat[column].map(value_map)\n",
    "    \n",
    "    return cat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244166d7",
   "metadata": {
    "papermill": {
     "duration": 0.009066,
     "end_time": "2025-04-28T23:18:01.764970",
     "exception": false,
     "start_time": "2025-04-28T23:18:01.755904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We define a custom function, ColumnTrans, to map categorical values into numerical indices. This is a form of Label Encoding, where each unique category in a column is replaced with a corresponding number.\n",
    "\n",
    "For instance, if a column has categories [\"Low\", \"Medium\", \"High\"], these will be transformed into [0, 1, 2]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9968b7",
   "metadata": {
    "papermill": {
     "duration": 0.009272,
     "end_time": "2025-04-28T23:18:01.783799",
     "exception": false,
     "start_time": "2025-04-28T23:18:01.774527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 6: Data Preprocessing - Transform Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c907242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:18:01.803636Z",
     "iopub.status.busy": "2025-04-28T23:18:01.803301Z",
     "iopub.status.idle": "2025-04-28T23:18:02.060348Z",
     "shell.execute_reply": "2025-04-28T23:18:02.059229Z"
    },
    "papermill": {
     "duration": 0.269257,
     "end_time": "2025-04-28T23:18:02.062455",
     "exception": false,
     "start_time": "2025-04-28T23:18:01.793198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Categorical Columns (first few rows):\n",
      "   Education  EmploymentType  MaritalStatus  HasMortgage  HasDependents  \\\n",
      "0          0               0              0            0              0   \n",
      "1          1               0              1            1              1   \n",
      "2          1               1              0            0              0   \n",
      "3          2               0              1            1              1   \n",
      "4          0               1              0            1              0   \n",
      "\n",
      "   LoanPurpose  HasCoSigner  \n",
      "0            0            0  \n",
      "1            0            0  \n",
      "2            1            1  \n",
      "3            2            1  \n",
      "4            1            1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Select the categorical columns (object type) from the DataFrame.\n",
    "cat = Data.select_dtypes(include='object')\n",
    "\n",
    "# Apply the custom ColumnTrans function to transform categorical columns into numerical format.\n",
    "cat = ColumnTrans(cat)\n",
    "\n",
    "# Verify the transformation by displaying the first few rows of the transformed categorical data.\n",
    "print(\"Transformed Categorical Columns (first few rows):\")\n",
    "print(cat.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6557ec40",
   "metadata": {
    "papermill": {
     "duration": 0.009259,
     "end_time": "2025-04-28T23:18:02.081710",
     "exception": false,
     "start_time": "2025-04-28T23:18:02.072451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We apply the ColumnTrans function to the categorical DataFrame, converting all categorical columns into numerical representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d2a1c6",
   "metadata": {
    "papermill": {
     "duration": 0.009315,
     "end_time": "2025-04-28T23:18:02.101281",
     "exception": false,
     "start_time": "2025-04-28T23:18:02.091966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 7: Data Preprocessing - Combining Numerical and Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fdf53d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:18:02.121467Z",
     "iopub.status.busy": "2025-04-28T23:18:02.121113Z",
     "iopub.status.idle": "2025-04-28T23:18:02.159493Z",
     "shell.execute_reply": "2025-04-28T23:18:02.158002Z"
    },
    "papermill": {
     "duration": 0.050517,
     "end_time": "2025-04-28T23:18:02.161319",
     "exception": false,
     "start_time": "2025-04-28T23:18:02.110802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame (first few rows):\n",
      "   Age  Income  LoanAmount  CreditScore  MonthsEmployed  NumCreditLines  \\\n",
      "0   56   85994       50587          520              80               4   \n",
      "1   69   50432      124440          458              15               1   \n",
      "2   46   84208      129188          451              26               3   \n",
      "3   32   31713       44799          743               0               3   \n",
      "4   60   20437        9139          633               8               4   \n",
      "\n",
      "   InterestRate  LoanTerm  DTIRatio  Default  Education  EmploymentType  \\\n",
      "0         15.23        36      0.44        0          0               0   \n",
      "1          4.81        60      0.68        0          1               0   \n",
      "2         21.17        24      0.31        1          1               1   \n",
      "3          7.07        24      0.23        0          2               0   \n",
      "4          6.51        48      0.73        0          0               1   \n",
      "\n",
      "   MaritalStatus  HasMortgage  HasDependents  LoanPurpose  HasCoSigner  \n",
      "0              0            0              0            0            0  \n",
      "1              1            1              1            0            0  \n",
      "2              0            0              0            1            1  \n",
      "3              1            1              1            2            1  \n",
      "4              0            1              0            1            1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Concatenate the numerical and transformed categorical features along the columns (axis=1).\n",
    "df = pd.concat([num, cat], axis=1)\n",
    "\n",
    "# Verify the combined DataFrame by displaying the first few rows.\n",
    "print(\"Combined DataFrame (first few rows):\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96fbdb1",
   "metadata": {
    "papermill": {
     "duration": 0.009383,
     "end_time": "2025-04-28T23:18:02.180646",
     "exception": false,
     "start_time": "2025-04-28T23:18:02.171263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We combine the numerical features and transformed categorical features into a single DataFrame. The concat() function merges them along the columns axis (axis=1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a2e0f0",
   "metadata": {
    "papermill": {
     "duration": 0.009303,
     "end_time": "2025-04-28T23:18:02.199640",
     "exception": false,
     "start_time": "2025-04-28T23:18:02.190337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 8: Data Preprocessing - Splitting Features and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f6f178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:18:02.220722Z",
     "iopub.status.busy": "2025-04-28T23:18:02.220386Z",
     "iopub.status.idle": "2025-04-28T23:18:02.238005Z",
     "shell.execute_reply": "2025-04-28T23:18:02.236911Z"
    },
    "papermill": {
     "duration": 0.030421,
     "end_time": "2025-04-28T23:18:02.239827",
     "exception": false,
     "start_time": "2025-04-28T23:18:02.209406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Features (X): (255347, 16)\n",
      "Shape of Target (y): (255347,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Separate features (X) from the target variable (y)\n",
    "x1 = df.drop(columns='Default')  # Features: All columns except 'Default'\n",
    "y1 = df['Default']  # Target: 'Default' column\n",
    "\n",
    "# Verify the separation by displaying the shapes of the features and target.\n",
    "print(\"Shape of Features (X):\", x1.shape)\n",
    "print(\"Shape of Target (y):\", y1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a727a49",
   "metadata": {
    "papermill": {
     "duration": 0.009385,
     "end_time": "2025-04-28T23:18:02.259247",
     "exception": false,
     "start_time": "2025-04-28T23:18:02.249862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We split the dataset into features (x1) and the target variable (y1). The target, 'Default', indicates whether a loan is defaulted (1) or not (0). This allows us to train a model to predict this target based on the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20341155",
   "metadata": {
    "papermill": {
     "duration": 0.009303,
     "end_time": "2025-04-28T23:18:02.278375",
     "exception": false,
     "start_time": "2025-04-28T23:18:02.269072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 9: Data Preprocessing - Balancing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbc2177b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:18:02.299647Z",
     "iopub.status.busy": "2025-04-28T23:18:02.299303Z",
     "iopub.status.idle": "2025-04-28T23:18:02.311993Z",
     "shell.execute_reply": "2025-04-28T23:18:02.310783Z"
    },
    "papermill": {
     "duration": 0.025417,
     "end_time": "2025-04-28T23:18:02.314033",
     "exception": false,
     "start_time": "2025-04-28T23:18:02.288616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling techniques initialized:\n",
      "RandomOverSampler: RandomOverSampler()\n",
      "RandomUnderSampler: RandomUnderSampler()\n",
      "SMOTE: SMOTE()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the resampling techniques\n",
    "ros = RandomOverSampler()  # Random Over-Sampling to balance the dataset by increasing the minority class.\n",
    "rus = RandomUnderSampler()  # Random Under-Sampling to balance the dataset by decreasing the majority class.\n",
    "smote = SMOTE()  # SMOTE (Synthetic Minority Over-sampling Technique) to generate synthetic examples for the minority class.\n",
    "\n",
    "# Verify that the resampling methods are correctly initialized\n",
    "print(\"Resampling techniques initialized:\")\n",
    "print(\"RandomOverSampler:\", ros)\n",
    "print(\"RandomUnderSampler:\", rus)\n",
    "print(\"SMOTE:\", smote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aecacd",
   "metadata": {
    "papermill": {
     "duration": 0.009554,
     "end_time": "2025-04-28T23:18:02.333900",
     "exception": false,
     "start_time": "2025-04-28T23:18:02.324346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We initialize three techniques for handling class imbalance:\n",
    "\n",
    "RandomOverSampler: Increases the minority class by randomly duplicating samples.\n",
    "\n",
    "RandomUnderSampler: Decreases the majority class by randomly removing samples.\n",
    "\n",
    "SMOTE: Uses Synthetic Minority Over-sampling Technique to create synthetic samples for the minority class.\n",
    "\n",
    "These methods are crucial for ensuring the model is not biased towards the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694cca19",
   "metadata": {
    "papermill": {
     "duration": 0.009512,
     "end_time": "2025-04-28T23:18:02.353581",
     "exception": false,
     "start_time": "2025-04-28T23:18:02.344069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 10: Balancing the Dataset - Applying Resampling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b7b45f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:18:02.375509Z",
     "iopub.status.busy": "2025-04-28T23:18:02.375102Z",
     "iopub.status.idle": "2025-04-28T23:18:03.156567Z",
     "shell.execute_reply": "2025-04-28T23:18:03.155533Z"
    },
    "papermill": {
     "duration": 0.794489,
     "end_time": "2025-04-28T23:18:03.158421",
     "exception": false,
     "start_time": "2025-04-28T23:18:02.363932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after RandomOverSampler (ROS): (451388, 16) (451388,)\n",
      "Shape after SMOTE: (451388, 16) (451388,)\n",
      "Shape after RandomUnderSampler (RUS): (451388, 16) (451388,)\n",
      "Final Balanced Dataset Shape (X): (451388, 16)\n",
      "Final Balanced Dataset Shape (Y): (451388,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Apply Random Over-Sampling to increase the minority class\n",
    "x2, y2 = ros.fit_resample(x1, y1)\n",
    "print(\"Shape after RandomOverSampler (ROS):\", x2.shape, y2.shape)\n",
    "\n",
    "# Apply SMOTE to generate synthetic samples for the minority class\n",
    "x3, y3 = smote.fit_resample(x2, y2)\n",
    "print(\"Shape after SMOTE:\", x3.shape, y3.shape)\n",
    "\n",
    "# Apply Random Under-Sampling to decrease the majority class\n",
    "x, y = rus.fit_resample(x3, y3)\n",
    "print(\"Shape after RandomUnderSampler (RUS):\", x.shape, y.shape)\n",
    "\n",
    "# Final balanced dataset\n",
    "print(\"Final Balanced Dataset Shape (X):\", x.shape)\n",
    "print(\"Final Balanced Dataset Shape (Y):\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a6b278",
   "metadata": {
    "papermill": {
     "duration": 0.009657,
     "end_time": "2025-04-28T23:18:03.178478",
     "exception": false,
     "start_time": "2025-04-28T23:18:03.168821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We apply the resampling techniques sequentially:\n",
    "\n",
    "First, we oversample the minority class using RandomOverSampler.\n",
    "\n",
    "Next, we apply SMOTE to generate synthetic samples.\n",
    "\n",
    "Finally, we undersample the majority class using RandomUnderSampler.\n",
    "\n",
    "This helps to balance the dataset before training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cefd559",
   "metadata": {
    "papermill": {
     "duration": 0.009644,
     "end_time": "2025-04-28T23:18:03.198143",
     "exception": false,
     "start_time": "2025-04-28T23:18:03.188499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 11: Data Splitting - Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cd67c27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:18:03.219353Z",
     "iopub.status.busy": "2025-04-28T23:18:03.219002Z",
     "iopub.status.idle": "2025-04-28T23:18:03.339047Z",
     "shell.execute_reply": "2025-04-28T23:18:03.337999Z"
    },
    "papermill": {
     "duration": 0.132906,
     "end_time": "2025-04-28T23:18:03.341010",
     "exception": false,
     "start_time": "2025-04-28T23:18:03.208104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Features (X_train): (361110, 16)\n",
      "Shape of Testing Features (X_test): (90278, 16)\n",
      "Shape of Training Target (y_train): (361110,)\n",
      "Shape of Testing Target (y_test): (90278,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split the balanced dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets to verify the split\n",
    "print(\"Shape of Training Features (X_train):\", x_train.shape)\n",
    "print(\"Shape of Testing Features (X_test):\", x_test.shape)\n",
    "print(\"Shape of Training Target (y_train):\", y_train.shape)\n",
    "print(\"Shape of Testing Target (y_test):\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3785a04a",
   "metadata": {
    "papermill": {
     "duration": 0.009889,
     "end_time": "2025-04-28T23:18:03.361217",
     "exception": false,
     "start_time": "2025-04-28T23:18:03.351328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We split the resampled dataset into training and testing sets. train_test_split() divides the data into two subsets:\n",
    "\n",
    "Training set (80%): Used to train the model.\n",
    "\n",
    "Testing set (20%): Used to evaluate the model's performance.\n",
    "\n",
    "The random_state=42 ensures reproducibility of the split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e91a75c",
   "metadata": {
    "papermill": {
     "duration": 0.009734,
     "end_time": "2025-04-28T23:18:03.381366",
     "exception": false,
     "start_time": "2025-04-28T23:18:03.371632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 12: Model Initialization - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33a5a439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:18:03.402747Z",
     "iopub.status.busy": "2025-04-28T23:18:03.402393Z",
     "iopub.status.idle": "2025-04-28T23:18:03.408590Z",
     "shell.execute_reply": "2025-04-28T23:18:03.407485Z"
    },
    "papermill": {
     "duration": 0.018854,
     "end_time": "2025-04-28T23:18:03.410239",
     "exception": false,
     "start_time": "2025-04-28T23:18:03.391385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier initialized with parameters:\n",
      "RandomForestClassifier(n_estimators=2000, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the Random Forest Classifier with 2000 estimators (trees)\n",
    "model = RandomForestClassifier(n_estimators=2000, random_state=42)\n",
    "\n",
    "# Display the model's parameters to verify the configuration\n",
    "print(\"Random Forest Classifier initialized with parameters:\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f03727",
   "metadata": {
    "papermill": {
     "duration": 0.0097,
     "end_time": "2025-04-28T23:18:03.430126",
     "exception": false,
     "start_time": "2025-04-28T23:18:03.420426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We initialize a Random Forest Classifier with 2000 estimators (trees). Random forests are ensembles of decision trees that improve accuracy and robustness by averaging predictions from multiple trees. The random_state=42 ensures reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73437f4f",
   "metadata": {
    "papermill": {
     "duration": 0.009656,
     "end_time": "2025-04-28T23:18:03.449893",
     "exception": false,
     "start_time": "2025-04-28T23:18:03.440237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 13: Model Training - Fitting the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a5938aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:18:03.471339Z",
     "iopub.status.busy": "2025-04-28T23:18:03.470971Z",
     "iopub.status.idle": "2025-04-28T23:54:06.954709Z",
     "shell.execute_reply": "2025-04-28T23:54:06.953723Z"
    },
    "papermill": {
     "duration": 2163.505653,
     "end_time": "2025-04-28T23:54:06.965640",
     "exception": false,
     "start_time": "2025-04-28T23:18:03.459987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete with Random Forest Classifier.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model using the training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Display a message to indicate that training is complete\n",
    "print(\"Model training complete with Random Forest Classifier.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab338d",
   "metadata": {
    "papermill": {
     "duration": 0.010158,
     "end_time": "2025-04-28T23:54:06.986045",
     "exception": false,
     "start_time": "2025-04-28T23:54:06.975887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We train the Random Forest model on the training data. The .fit() method uses the features (x_train) and the corresponding target labels (y_train) to build the model. This process involves decision trees learning patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269bd15c",
   "metadata": {
    "papermill": {
     "duration": 0.009851,
     "end_time": "2025-04-28T23:54:07.006052",
     "exception": false,
     "start_time": "2025-04-28T23:54:06.996201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 14: Model Prediction - Predicting on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06d7f52d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:54:07.027552Z",
     "iopub.status.busy": "2025-04-28T23:54:07.027193Z",
     "iopub.status.idle": "2025-04-28T23:55:24.693545Z",
     "shell.execute_reply": "2025-04-28T23:55:24.692466Z"
    },
    "papermill": {
     "duration": 77.688351,
     "end_time": "2025-04-28T23:55:24.704554",
     "exception": false,
     "start_time": "2025-04-28T23:54:07.016203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions: (90278,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "prediction = model.predict(x_test)\n",
    "\n",
    "# Display the shape of the predictions to verify\n",
    "print(\"Shape of predictions:\", prediction.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c212cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:55:24.726787Z",
     "iopub.status.busy": "2025-04-28T23:55:24.726412Z",
     "iopub.status.idle": "2025-04-28T23:55:24.733025Z",
     "shell.execute_reply": "2025-04-28T23:55:24.732045Z"
    },
    "papermill": {
     "duration": 0.019803,
     "end_time": "2025-04-28T23:55:24.734788",
     "exception": false,
     "start_time": "2025-04-28T23:55:24.714985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44334"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the data was imbalanced looking to see if the model predicts both values or needs more work.\n",
    "(prediction == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbc216bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:55:24.758086Z",
     "iopub.status.busy": "2025-04-28T23:55:24.757629Z",
     "iopub.status.idle": "2025-04-28T23:55:24.764258Z",
     "shell.execute_reply": "2025-04-28T23:55:24.763205Z"
    },
    "papermill": {
     "duration": 0.02016,
     "end_time": "2025-04-28T23:55:24.766182",
     "exception": false,
     "start_time": "2025-04-28T23:55:24.746022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45944"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prediction == 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39186729",
   "metadata": {
    "papermill": {
     "duration": 0.010375,
     "end_time": "2025-04-28T23:55:24.787503",
     "exception": false,
     "start_time": "2025-04-28T23:55:24.777128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After training, we use the .predict() method to generate predictions for the test set (x_test). This is the model’s attempt to predict whether loans in the test data will default or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6671cf",
   "metadata": {
    "papermill": {
     "duration": 0.010275,
     "end_time": "2025-04-28T23:55:24.808905",
     "exception": false,
     "start_time": "2025-04-28T23:55:24.798630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STEP 15: Model Evaluation - Precision, Recall, F1, and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0368a736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T23:55:24.831625Z",
     "iopub.status.busy": "2025-04-28T23:55:24.831279Z",
     "iopub.status.idle": "2025-04-28T23:55:24.979663Z",
     "shell.execute_reply": "2025-04-28T23:55:24.978333Z"
    },
    "papermill": {
     "duration": 0.162181,
     "end_time": "2025-04-28T23:55:24.981794",
     "exception": false,
     "start_time": "2025-04-28T23:55:24.819613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9898\n",
      "Precision: 0.9814\n",
      "Recall: 0.9984\n",
      "F1 Score: 0.9899\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import the evaluation metrics from sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1 = f1_score(y_test, prediction)\n",
    "\n",
    "# Display the metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f698ea62",
   "metadata": {
    "papermill": {
     "duration": 0.010405,
     "end_time": "2025-04-28T23:55:25.003049",
     "exception": false,
     "start_time": "2025-04-28T23:55:24.992644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here, we evaluate the model’s performance by calculating:\n",
    "\n",
    "Accuracy: Proportion of correct predictions.\n",
    "\n",
    "Precision: Proportion of true positive predictions out of all positive predictions.\n",
    "\n",
    "Recall: Proportion of true positives correctly identified from all actual positives.\n",
    "\n",
    "F1 Score: Harmonic mean of precision and recall, providing a balance between them.\n",
    "\n",
    "These metrics help us assess the model’s reliability and robustness, especially in the context of imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ac155",
   "metadata": {
    "papermill": {
     "duration": 0.010345,
     "end_time": "2025-04-28T23:55:25.024197",
     "exception": false,
     "start_time": "2025-04-28T23:55:25.013852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3725579,
     "sourceId": 6453754,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2252.938491,
   "end_time": "2025-04-28T23:55:26.361322",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-28T23:17:53.422831",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
